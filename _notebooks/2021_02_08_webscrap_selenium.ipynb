{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFw0aMiBYHbl"
   },
   "source": [
    "# pt-BR | Web scraping com Selenium\n",
    "> \"Selenium & Python.\"\n",
    "  \n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [fastpages, jupyter]\n",
    "- hide: false\n",
    "- author: leticiaplang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xb-HpEIYK_8"
   },
   "source": [
    "O **web scraping** é um modo de coletarmos dados de\n",
    "uma fonte web e armazená-lo de uma forma que permita \n",
    "a exploração deles para retirada de insights ou para \n",
    "utilização de técnicas de machine learning, por exemplo.\n",
    "\n",
    "Aborarei esse conetúdo em três  partes, cada uma \n",
    "abordando uma das maneiras de realizarmos o processo:\n",
    "**Selenium**, **Beautiful Soup** e **Requests**. \n",
    "Para todos utilizo **Python** e um pouco de conhecimento de web e HTML. \n",
    "\n",
    "Bora lá! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPDtKbcIZGsf"
   },
   "source": [
    "### Web scraping com Selenium e Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3hBM5URYLCm"
   },
   "source": [
    "Para inciarmos o processo é importante realizar todas as instalações ou importações das bibliotecas ou pacotes que iremos utilizar. \n",
    "* **Webdriver** que é necessário para navegarmos pela página web de modo automatizado. É preciso realizar o download dele conforme o browser que você utiliza e a versão dele instalada por meio desse [site](https://www.selenium.dev/documentation/webdriver/getting_started/install_drivers/) e colocar o programa na mesma pasta do documento/notebook que você estará rodando.\n",
    "* Utilizarei o browser do chrome, logo importarei também o **Options** para que eu possa definir navegação privada/incognito e tamanho da janela.\n",
    "* **Pandas** é essencial para transformarmos os dados em estrutura de data frame, que possui mesma estrutura de uma tabela (clolunas e linhas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFcx_NlmY5oK"
   },
   "outputs": [],
   "source": [
    "# Importações\n",
    "import time  #se necessário utilizar um tempo de espera para rodar as próximas células\n",
    "from selenium import webdriver #para conseguirmos navegar de modo automatizado pela página web\n",
    "from selenium.webdriver.chrome.options import Options #configurar incognito\n",
    "import pandas as pd #dataframe e exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jG--UJJecuYy"
   },
   "outputs": [],
   "source": [
    "# Definição de Janela Desktop\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PY_UNemc1Bc"
   },
   "outputs": [],
   "source": [
    "# Definindo o Driver para abrir a janela de navegação\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msrxsknBdNDv"
   },
   "source": [
    "A partir desse ponto definimos a página que gostaremos de estar explorando para captar os dados. \n",
    "\n",
    "No meu caso, utilizei o web scraping para puxar os dados dos novos contatos do linkedin (nome, área de atuação e horário da aceitação). Já insiro também uma células com variáveis para login e senha (sem tratamento adequado para proteção desses dados).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkPUJS7Qc9kT"
   },
   "outputs": [],
   "source": [
    "## Definindo URL e solicitando acesso\n",
    "url = \"https://www.linkedin.com/login/pt?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin\"\n",
    "driver.get(url)\n",
    "time.sleep(2) #utilizado para dar tempo extra para carregamento da página antes de rodar a próxima célula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7rdN_78eQV5"
   },
   "outputs": [],
   "source": [
    "## Dados login\n",
    "login = 'xpto@gmail.com' #exemplo ilustrativo. Trocar pelo seu e atentar para não compartilhar o dados\n",
    "password ='x1p2t3o' #exemplo ilustrativo. Trocar pelo seu e atentar para não compartilhar o dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o0sbCfjYLFL"
   },
   "source": [
    "Para **inspecionar o site** você pode clicar com o botão direito e após clicar em inspecionar elemento. Abrirá uma janela com toda a estrtura do site em html com aspectos em outras linguagens como java ou c. \n",
    "\n",
    "O objetivo nesse momento é você identificar o que define o elemento que você quer interagir.\n",
    "\n",
    "No meu caso, quero clicar no espaço para login, então clico para inspecionar o espaço de preenchimento do usuário e busco o que define adequadamente esse espaço, mas muitas vezes precisamos descobrir na tentativa e erro mesmo.\n",
    "\n",
    "O Selenium possui diversos comandos para solicitarmos a identificação de determinada parte do site. Sempre iremos iniciar com o driver, uma vez que este define a janela que estamos navegando.\n",
    "\n",
    "identificação por id\n",
    "  \n",
    "    var = driver.find_elements_by_id('inserir aqui')\n",
    "\n",
    "identificação por nome\n",
    "    \n",
    "    var = driver.find_elements_by_name('inserir aqui')\n",
    "\n",
    "identificação por classe\n",
    "\n",
    "    var = driver.find_elements_by_class_name('inserir aqui')\n",
    "\n",
    "identificação por texto especifico\n",
    "\n",
    "    var = driver.find_elements_by_link_text('inserir aqui')\n",
    "\n",
    "identificação por parte do texto\n",
    "\n",
    "    var = driver.find_elements_by_partial_link_text('inserir aqui')\n",
    "\n",
    "identificação por seletor css\n",
    "\n",
    "    var = driver.find_elements_by_css_selector('inserir aqui') \n",
    "\n",
    "identificação por caminho Xpath\n",
    "\n",
    "    var = driver.find_elements_by_xpath('inserir aqui')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fux6x9aDYLHw"
   },
   "source": [
    "Após identificarmos o elemento adequadamente, podemos solicitar inserir algum dado ou podemos solicitar que clique no botão que identificamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhXC_vLUh3hy"
   },
   "outputs": [],
   "source": [
    "# Inserindo um dado no local\n",
    "usuario =  driver.find_elements_by_class_name('inserir aqui') #encontrando o local para preenchimento\n",
    "usuario.send_keys(login) #solicitando inserir o dado da variável login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdvWrfmBimGk"
   },
   "outputs": [],
   "source": [
    "# Clicando em um botão\n",
    "botao_entrar = driver.find_elements_by_xpath('inserir aqui') #encontrar o botão\n",
    "botao_entrar.click() #solicitar click no botão\n",
    "time.sleep(3) #aguardar 3segundos para rodar a próxima célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ZoZTEQYLKV"
   },
   "source": [
    "Você vai precisar realizar esse processo até chegar à página que você quer extrair os dados. Após o login, fui na 'minha rede' e 'conexões'. \n",
    "\n",
    "No linkedin é necessário rolar a página para carregar mais dados, então realizei a solicitação para rolar até encontrar o útlimo contato que havia visto. para rodar até o final, apenas inserir o elemento que englobe todos os contato na variável último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-bPwv7ChkTl"
   },
   "outputs": [],
   "source": [
    "# Rolagem\n",
    "ultimo = driver.find_element_by_xpath('inserir aqui')\n",
    "\n",
    "while True:\n",
    "    # Realizar a rolagem\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Aguardar 1 segundo\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    _ = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if _ == ultimo:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JVITlEOYLMr"
   },
   "source": [
    "Agora necessitamos realizar a retirada dos dados da página. Por meio do código abaixo você capta os dados do elemento definido e após extrai o dados em formato de texto. Realizei isso para nome, cargo e horário conforme já havia dito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCu7Mgx-YEf0"
   },
   "outputs": [],
   "source": [
    "names = people.find_elements_by_css_selector('.mn-connection-card__name')\n",
    "name = [n.text for n in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMFCYrG4l9Yl"
   },
   "outputs": [],
   "source": [
    "cargos = people.find_elements_by_css_selector('.mn-connection-card__occupation')\n",
    "cargo = [c.text for c in cargos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JM2UW960l9QM"
   },
   "outputs": [],
   "source": [
    "horarios = people.find_elements_by_css_selector('.time-badge')\n",
    "horario = [h.text for h in horarios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwjYDVgjYLPR"
   },
   "source": [
    "Por último precisamos finalizar o driver e construir o data frame para realizar o download dele para máquina local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTjwCfXOmbs4"
   },
   "outputs": [],
   "source": [
    "# Finalizando o driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9A9zhFembvR"
   },
   "outputs": [],
   "source": [
    "# Criando o data frame e realizando o download para a máquina local\n",
    "df = pd.DataFrame({'nome':name, 'cargo':cargo, 'horario':horario})\n",
    "df.to_csv('linkedin.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021-02-08-webscrapingp1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
